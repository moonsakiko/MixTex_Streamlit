# æ–‡ä»¶å: streamlit_app.py

import streamlit as st
from PIL import Image
import numpy as np
import onnxruntime as ort
from transformers import AutoTokenizer, AutoImageProcessor
import re
import io

# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(page_title="MixTeX LaTeX OCR åœ¨çº¿å·¥å…·", page_icon="ğŸ“")
st.title("ğŸ“ MixTeX - LaTeX/å…¬å¼/è¡¨æ ¼ OCR")
st.info("ä¸Šä¼ ä¸€å¼ åŒ…å«å…¬å¼ã€è¡¨æ ¼æˆ–ä¸­è‹±æ–‡æ–‡æœ¬çš„å›¾ç‰‡ï¼ŒAIå°†è‡ªåŠ¨è¯†åˆ«å¹¶è¿”å›LaTeXæˆ–çº¯æ–‡æœ¬ç»“æœã€‚")
st.warning("æ¨¡å‹è¾ƒå¤§ï¼Œé¦–æ¬¡åŠ è½½å¯èƒ½éœ€è¦1-2åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚")

# ===================================================================
# ---                         æ ¸å¿ƒé€»è¾‘éƒ¨åˆ† (æ— éœ€æ”¹åŠ¨)                 ---
# ===================================================================

@st.cache_resource
def load_model(model_dir="onnx"):
    """
    åŠ è½½æ‰€æœ‰å¿…è¦çš„æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚
    æ¨¡å‹æ–‡ä»¶éœ€è¦æ”¾åœ¨ä¸€ä¸ªåä¸º 'onnx' çš„æ–‡ä»¶å¤¹é‡Œã€‚
    """
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_dir)
        feature_extractor = AutoImageProcessor.from_pretrained(model_dir)
        providers = ['CPUExecutionProvider']
        encoder_sess = ort.InferenceSession(f"{model_dir}/encoder_model.onnx", providers=providers)
        decoder_sess = ort.InferenceSession(f"{model_dir}/decoder_model_merged.onnx", providers=providers)
        return tokenizer, feature_extractor, encoder_sess, decoder_sess
    except Exception as e:
        # å…¼å®¹ä¸åŒéƒ¨ç½²ç¯å¢ƒçš„è·¯å¾„
        try:
            abs_model_dir = f"/app/{model_dir}"
            tokenizer = AutoTokenizer.from_pretrained(abs_model_dir)
            feature_extractor = AutoImageProcessor.from_pretrained(abs_model_dir)
            providers = ['CPUExecutionProvider']
            encoder_sess = ort.InferenceSession(f"{abs_model_dir}/encoder_model.onnx", providers=providers)
            decoder_sess = ort.InferenceSession(f"{abs_model_dir}/decoder_model_merged.onnx", providers=providers)
            return tokenizer, feature_extractor, encoder_sess, decoder_sess
        except Exception as e2:
            st.error(f"åœ¨ {model_dir} å’Œ {abs_model_dir} éƒ½æ— æ³•åŠ è½½æ¨¡å‹ï¼è¯·ç¡®ä¿'onnx'æ–‡ä»¶å¤¹åŠå†…å®¹å·²ä¸Šä¼ ã€‚é”™è¯¯: {e2}")
            return None


def pad_image(img, out_size=(448, 448)):
    """å°†å›¾ç‰‡ç¼©æ”¾å¹¶å¡«å……åˆ°ç›®æ ‡å°ºå¯¸"""
    x_img, y_img = out_size
    bg = Image.new("RGB", (x_img, y_img), (255, 255, 255))
    w, h = img.size
    if w > x_img or h > y_img:
        scale = min(x_img / w, y_img / h)
        nw, nh = int(w * scale), int(h * scale)
        img = img.resize((nw, nh), Image.LANCZOS)
    
    w, h = img.size
    x = (x_img - w) // 2
    y = (y_img - h) // 2
    bg.paste(img, (x, y))
    return bg

def check_repetition(s, repeats=12):
    """æ£€æŸ¥ç”Ÿæˆæ–‡æœ¬ä¸­æ˜¯å¦æœ‰è¿‡åº¦é‡å¤"""
    if len(s) < repeats: return False
    for pattern_length in range(1, len(s) // repeats + 1):
        pattern = s[-pattern_length:]
        if s[-repeats * pattern_length:] == pattern * repeats:
            return True
    return False

def stream_inference(image, model, max_length=512, num_layers=6, hidden_size=768, heads=12, batch_size=1):
    """æµå¼æ¨ç†å‡½æ•°ï¼Œé€ä¸ªtokenç”Ÿæˆç»“æœ"""
    tokenizer, feature_extractor, enc_session, dec_session = model
    head_size = hidden_size // heads
    
    inputs = feature_extractor(image, return_tensors="np").pixel_values
    enc_out = enc_session.run(None, {"pixel_values": inputs})[0]
    
    dec_in = {
        "input_ids": tokenizer("<s>", return_tensors="np").input_ids.astype(np.int64),
        "encoder_hidden_states": enc_out,
        "use_cache_branch": np.array([True], dtype=bool),
        **{
            f"past_key_values.{i}.{t}": np.zeros(
                (batch_size, heads, 0, head_size), dtype=np.float32
            )
            for i in range(num_layers)
            for t in ["key", "value"]
        },
    }
    
    generated = ""
    for _ in range(max_length):
        outs = dec_session.run(None, dec_in)
        next_id = np.argmax(outs[0][:, -1, :], axis=-1)
        
        if next_id[0] == tokenizer.eos_token_id:
            break
            
        token_text = tokenizer.decode(next_id, skip_special_tokens=True)
        yield token_text
        
        generated += token_text
        if check_repetition(generated, 21):
            break
            
        dec_in.update(
            {
                "input_ids": next_id[:, None],
                **{
                    f"past_key_values.{i}.{t}": outs[i * 2 + 1 + j]
                    for i in range(num_layers)
                    for j, t in enumerate(["key", "value"])
                },
            }
        )

# --- â¬‡ï¸â¬‡ï¸â¬‡ï¸ æ–°å¢ï¼šæ ¼å¼è½¬æ¢å‡½æ•° â¬‡ï¸â¬‡ï¸â¬‡ï¸ ---
def format_latex_output(text, mode):
    """æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ¨¡å¼ï¼Œè½¬æ¢LaTeXè¾“å‡ºæ ¼å¼"""
    if mode == "ä¸“ä¸šæ¨¡å¼ (Align)":
        # å°† \[...\] æ›¿æ¢ä¸º align* ç¯å¢ƒï¼Œä»¥æ­£ç¡®å¤„ç† & å’Œ \\
        return text.replace("\\[", "\\begin{align*}").replace("\\]", "\\end{align*}")
    
    elif mode == "å…¼å®¹æ¨¡å¼ (Split)":
        # è¿™æ˜¯ä¸€ä¸ªæ›´é€šç”¨çš„æ¨¡å¼ï¼Œå°†ä¸€ä¸ªå¤šè¡Œå…¬å¼ï¼Œæ‹†åˆ†æˆå¤šä¸ªç‹¬ç«‹çš„å•è¡Œå…¬å¼
        # å…ˆç§»é™¤å¤–å±‚çš„ \[ å’Œ \]
        content = text.strip()
        if content.startswith("\\[") and content.endswith("\\]"):
            content = content[2:-2].strip()
        
        # æŒ‰ \\ (æ¢è¡Œç¬¦) æ‹†åˆ†
        lines = content.split('\\\\')
        
        # ä¸ºæ¯ä¸€è¡Œéƒ½å¥—ä¸Š $$...$$ï¼Œå¹¶ç§»é™¤é‡Œé¢çš„ &
        formatted_lines = [f"$$ {line.replace('&', '').strip()} $$" for line in lines if line.strip()]
        return "\n".join(formatted_lines)
    
    return text # é»˜è®¤è¿”å›åŸå§‹ç»“æœ

# ===================================================================
# ---                         å‰ç«¯ç•Œé¢éƒ¨åˆ† (æœ€ç»ˆå‡çº§ç‰ˆ)                 ---
# ===================================================================

# åŠ è½½æ¨¡å‹ (åªä¼šæ‰§è¡Œä¸€æ¬¡)
model = load_model()

if model:
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶ (æ”¯æŒPNG, JPG, JPEG)", type=["png", "jpg", "jpeg"])

    if uploaded_file:
        try:
            img = Image.open(uploaded_file).convert("RGB")
            
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("å›¾ç‰‡é¢„è§ˆ")
                st.image(img, caption="ä¸Šä¼ å›¾ç‰‡")
            
            with col2:
                st.subheader("è¯†åˆ«ç»“æœ")
                if st.button("å¼€å§‹è¯†åˆ«", use_container_width=True):
                    with st.spinner("AI æ­£åœ¨è¯†åˆ«ä¸­..."):
                        img_padded = pad_image(img)
                        
                        # å®Œæ•´æ¥æ”¶æ‰€æœ‰æµå¼è¾“å‡º
                        result_pieces = []
                        for piece in stream_inference(img_padded, model):
                            result_pieces.append(piece)
                        
                        # å°†ç¢ç‰‡æ‹¼æ¥æˆæœ€ç»ˆçš„åŸå§‹ç»“æœ
                        raw_result = "".join(result_pieces)

                        # åœ¨ session_state ä¸­ä¿å­˜åŸå§‹ç»“æœï¼Œä»¥ä¾¿åç»­åˆ‡æ¢æ ¼å¼
                        st.session_state.raw_result = raw_result
                    
                    st.success("è¯†åˆ«å®Œæˆï¼")

                # --- â¬‡ï¸â¬‡ï¸â¬‡ï¸ æ–°å¢ï¼šç»“æœæ˜¾ç¤ºä¸æ ¼å¼åˆ‡æ¢UI â¬‡ï¸â¬‡ï¸â¬‡ï¸ ---
                # åªæœ‰å½“è¯†åˆ«ç»“æœå­˜åœ¨æ—¶ï¼Œæ‰æ˜¾ç¤ºè¿™éƒ¨åˆ†
                if "raw_result" in st.session_state and st.session_state.raw_result:
                    
                    # åˆ›å»ºä¸€ä¸ªé€‰æ‹©æ¡†ï¼Œè®©ç”¨æˆ·é€‰æ‹©è¾“å‡ºæ ¼å¼
                    output_mode = st.selectbox(
                        "é€‰æ‹©è¾“å‡ºæ ¼å¼",
                        ["ä¸“ä¸šæ¨¡å¼ (Align)", "å…¼å®¹æ¨¡å¼ (Split)"],
                        help="ä¸“ä¸šæ¨¡å¼ä¿ç•™Alignç¯å¢ƒï¼Œé€‚åˆLaTeXç¼–è¾‘å™¨ã€‚å…¼å®¹æ¨¡å¼å°†å¤šè¡Œå…¬å¼æ‹†åˆ†ä¸ºå¤šä¸ªå•è¡Œå…¬å¼ï¼Œé€‚åˆObsidianç­‰Markdownå·¥å…·ã€‚"
                    )

                    # æ ¹æ®ç”¨æˆ·çš„é€‰æ‹©ï¼Œæ ¼å¼åŒ–æœ€ç»ˆçš„è¾“å‡ºæ–‡æœ¬
                    formatted_result = format_latex_output(st.session_state.raw_result, output_mode)
                    
                    # ç”¨ä¸€ä¸ªä»£ç æ¡†æ˜¾ç¤ºæ ¼å¼åŒ–åçš„ç»“æœï¼Œæ–¹ä¾¿å¤åˆ¶
                    st.code(formatted_result, language="latex")

        except Exception as e:
            st.error(f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {e}")
else:
    st.error("æ¨¡å‹æœªèƒ½åŠ è½½ï¼Œåº”ç”¨æ— æ³•è¿è¡Œã€‚è¯·æ£€æŸ¥æ—¥å¿—ã€‚")